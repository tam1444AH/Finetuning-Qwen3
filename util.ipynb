{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNjDfthEp7nm4SIx3LPNSBI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tam1444AH/UH-Insure-NSA/blob/main/util.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h67W1rpmcrjf"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Helper function to get token ids of the special tokens for prefix, suffix and middle for FIM transformations.\n",
        "@functools.lru_cache(maxsize=None)\n",
        "def get_fim_token_ids(tokenizer):\n",
        "    try:\n",
        "        FIM_PREFIX, FIM_MIDDLE, FIM_SUFFIX, FIM_PAD = tokenizer.special_tokens_map[\"additional_special_tokens\"][1:5]\n",
        "        suffix_tok_id, prefix_tok_id, middle_tok_id, pad_tok_id = (\n",
        "            tokenizer.vocab[tok] for tok in [FIM_SUFFIX, FIM_PREFIX, FIM_MIDDLE, FIM_PAD]\n",
        "        )\n",
        "    except KeyError:\n",
        "        suffix_tok_id, prefix_tok_id, middle_tok_id, pad_tok_id = None, None, None, None\n",
        "    return suffix_tok_id, prefix_tok_id, middle_tok_id, pad_tok_id\n",
        "\n",
        "\n",
        "## Adapted from https://github.com/bigcode-project/Megatron-LM/blob/6c4bf908df8fd86b4977f54bf5b8bd4b521003d1/megatron/data/gpt_dataset.py\n",
        "def permute(\n",
        "    sample,\n",
        "    np_rng,\n",
        "    suffix_tok_id,\n",
        "    prefix_tok_id,\n",
        "    middle_tok_id,\n",
        "    pad_tok_id,\n",
        "    fim_rate=0.5,\n",
        "    fim_spm_rate=0.5,\n",
        "    truncate_or_pad=False,\n",
        "):\n",
        "    \"\"\"\n",
        "    Take in a sample (list of tokens) and perform a FIM transformation on it with a probability of fim_rate, using two FIM modes:\n",
        "    PSM and SPM (with a probability of fim_spm_rate).\n",
        "    \"\"\"\n",
        "\n",
        "    # The if condition will trigger with the probability of fim_rate\n",
        "    # This means FIM transformations will apply to samples with a probability of fim_rate\n",
        "    if np_rng.binomial(1, fim_rate):\n",
        "\n",
        "        # Split the sample into prefix, middle, and suffix, based on randomly generated indices stored in the boundaries list.\n",
        "        boundaries = list(np_rng.randint(low=0, high=len(sample) + 1, size=2))\n",
        "        boundaries.sort()\n",
        "\n",
        "        prefix = np.array(sample[: boundaries[0]], dtype=np.int64)\n",
        "        middle = np.array(sample[boundaries[0] : boundaries[1]], dtype=np.int64)\n",
        "        suffix = np.array(sample[boundaries[1] :], dtype=np.int64)\n",
        "\n",
        "        if truncate_or_pad:\n",
        "            # calculate the new total length of the sample, taking into account tokens indicating prefix, middle, and suffix\n",
        "            new_length = suffix.shape[0] + prefix.shape[0] + middle.shape[0] + 3\n",
        "            diff = new_length - len(sample)\n",
        "\n",
        "            # trancate or pad if there's a difference in length between the new length and the original\n",
        "            if diff > 0:\n",
        "                if suffix.shape[0] <= diff:\n",
        "                    return sample, np_rng\n",
        "                suffix = suffix[: suffix.shape[0] - diff]\n",
        "            elif diff < 0:\n",
        "                suffix = np.concatenate([suffix, np.full((-1 * diff), pad_tok_id)])\n",
        "\n",
        "        # With the probability of fim_spm_rateapply SPM variant of FIM transformations\n",
        "        # SPM: suffix, prefix, middle\n",
        "        if np_rng.binomial(1, fim_spm_rate):\n",
        "            new_sample = np.concatenate(\n",
        "                [\n",
        "                    [prefix_tok_id, suffix_tok_id],\n",
        "                    suffix,\n",
        "                    [middle_tok_id],\n",
        "                    prefix,\n",
        "                    middle,\n",
        "                ]\n",
        "            )\n",
        "        # Otherwise, apply the PSM variant of FIM transformations\n",
        "        # PSM: prefix, suffix, middle\n",
        "        else:\n",
        "\n",
        "            new_sample = np.concatenate(\n",
        "                [\n",
        "                    [prefix_tok_id],\n",
        "                    prefix,\n",
        "                    [suffix_tok_id],\n",
        "                    suffix,\n",
        "                    [middle_tok_id],\n",
        "                    middle,\n",
        "                ]\n",
        "            )\n",
        "    else:\n",
        "        # don't apply FIM transformations\n",
        "        new_sample = sample\n",
        "\n",
        "    return list(new_sample), np_rng"
      ]
    }
  ]
}